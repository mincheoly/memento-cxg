Tasks:

- Add unit tests and validation logic for estimators cube
- Acceptance tests for DE results (real data, human-validated, automated); see https://github.com/yelabucsf/scrna-parameter-estimation/blob/master/lupus/cxg_comparison/cellxgene_comparison.ipynb
- Possibly, build an official memento pip library, from which census imports relevant code to build and perform DE
- Add organism to cube as dim? (for query efficiency)

Questions:

- Which implementation of the estimator-based memento code should be used? cellxgene_comparison.ipynb or hypothesis_test.ipynb?
[Use hypothesis_test.ipynb. The cellxgene_comparison.ipynb code was more special case for comparing a single donor; however it does output the "var" computations as well, which could be worth including in the final solution]

- How/where in hypothesis_test.ipynb comparing two _sets_ of cells?
[This split is determined by two-valued treatment column, where the current implementation assumed the first column (0) is the treatment column]

- Is "cell type" always the "treatment"? [No]
- Any combination of the obs attributes should be selectable as covariates? [Yes]

estimators, treatment_variable
any set of estimator obs variables should be used as treatment "group"

[Decision: take one obs attr as the treatment variable, assume all others as covariates. Treatment variable does *not* have to be cell_type.]

- *** In hypothesis_test.ipynb, is it okay to aggregate `mean` and `sem` using `mean` func? This is necessary to build the pivot table. If not, should we remove these as dimensions from the estimators cube?
- In cellxgene_comparison.ipynb, the merge operation to join the two sets of cells of feature_id only makes sense if the feature_ids are unique. This depends upon the query filter used. Is it mathematically valid to group on feature_id and further aggregate the rows?

[We should not merge, but rather extend the "design" matrix to break out the duplicative attributes into the matrix as additional columns.]

- Can we eliminate unused estimators from cube? min (always 0?), max, sum, sev
[Yes, but let's keep the ability to add them to cube builds that will be for exploration and further algo development]

- Is a p-value of 0 an error? Precision/data/computation problem? Ignorable?
[Likely just a pandas display artifact]
